{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.display.max_columns = None\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('figure', figsize=[10,5])\n",
    "import mlrose_hiive\n",
    "from sklearn.metrics import f1_score\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      "class                      5000 non-null int64\n",
      "Alcohol                    5000 non-null float64\n",
      "Malic_acid                 5000 non-null float64\n",
      "Ash                        5000 non-null float64\n",
      "Alcalinity_of_ash          5000 non-null float64\n",
      "Magnesium                  5000 non-null float64\n",
      "Total_phenols              5000 non-null float64\n",
      "Flavanoids                 5000 non-null float64\n",
      "Nonflavanoid_phenols       5000 non-null float64\n",
      "Proanthocyanins            5000 non-null float64\n",
      "Color_intensity            5000 non-null float64\n",
      "Hue                        5000 non-null float64\n",
      "Od_Hod_of_diluted_wines    5000 non-null float64\n",
      "Proline                    5000 non-null float64\n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 547.0 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>Od_Hod_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.761443</td>\n",
       "      <td>0.972960</td>\n",
       "      <td>2.191146</td>\n",
       "      <td>14.349954</td>\n",
       "      <td>106.525734</td>\n",
       "      <td>2.288580</td>\n",
       "      <td>2.584551</td>\n",
       "      <td>0.418044</td>\n",
       "      <td>1.862804</td>\n",
       "      <td>3.086808</td>\n",
       "      <td>1.169861</td>\n",
       "      <td>2.819086</td>\n",
       "      <td>850.678431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11.897923</td>\n",
       "      <td>1.297780</td>\n",
       "      <td>2.199666</td>\n",
       "      <td>17.478054</td>\n",
       "      <td>104.205421</td>\n",
       "      <td>2.716657</td>\n",
       "      <td>1.855066</td>\n",
       "      <td>0.318077</td>\n",
       "      <td>1.029640</td>\n",
       "      <td>9.103668</td>\n",
       "      <td>1.353718</td>\n",
       "      <td>2.780333</td>\n",
       "      <td>332.922006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12.659632</td>\n",
       "      <td>1.748552</td>\n",
       "      <td>2.438597</td>\n",
       "      <td>21.584696</td>\n",
       "      <td>88.079451</td>\n",
       "      <td>1.919476</td>\n",
       "      <td>0.681341</td>\n",
       "      <td>0.538078</td>\n",
       "      <td>1.327974</td>\n",
       "      <td>8.803633</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>1.569951</td>\n",
       "      <td>633.531687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13.054828</td>\n",
       "      <td>1.817559</td>\n",
       "      <td>1.893926</td>\n",
       "      <td>15.390157</td>\n",
       "      <td>108.589893</td>\n",
       "      <td>2.662509</td>\n",
       "      <td>2.815723</td>\n",
       "      <td>0.278535</td>\n",
       "      <td>1.473812</td>\n",
       "      <td>6.386732</td>\n",
       "      <td>0.820398</td>\n",
       "      <td>3.694865</td>\n",
       "      <td>880.103325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>11.769431</td>\n",
       "      <td>3.017528</td>\n",
       "      <td>3.013448</td>\n",
       "      <td>17.081528</td>\n",
       "      <td>86.525235</td>\n",
       "      <td>2.224963</td>\n",
       "      <td>0.846229</td>\n",
       "      <td>0.286065</td>\n",
       "      <td>1.644007</td>\n",
       "      <td>10.383464</td>\n",
       "      <td>0.734288</td>\n",
       "      <td>2.747013</td>\n",
       "      <td>475.152492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class    Alcohol  Malic_acid       Ash  Alcalinity_of_ash   Magnesium  \\\n",
       "0      1  13.761443    0.972960  2.191146          14.349954  106.525734   \n",
       "1      2  11.897923    1.297780  2.199666          17.478054  104.205421   \n",
       "2      3  12.659632    1.748552  2.438597          21.584696   88.079451   \n",
       "3      1  13.054828    1.817559  1.893926          15.390157  108.589893   \n",
       "4      3  11.769431    3.017528  3.013448          17.081528   86.525235   \n",
       "\n",
       "   Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  \\\n",
       "0       2.288580    2.584551              0.418044         1.862804   \n",
       "1       2.716657    1.855066              0.318077         1.029640   \n",
       "2       1.919476    0.681341              0.538078         1.327974   \n",
       "3       2.662509    2.815723              0.278535         1.473812   \n",
       "4       2.224963    0.846229              0.286065         1.644007   \n",
       "\n",
       "   Color_intensity       Hue  Od_Hod_of_diluted_wines     Proline  \n",
       "0         3.086808  1.169861                 2.819086  850.678431  \n",
       "1         9.103668  1.353718                 2.780333  332.922006  \n",
       "2         8.803633  0.643678                 1.569951  633.531687  \n",
       "3         6.386732  0.820398                 3.694865  880.103325  \n",
       "4        10.383464  0.734288                 2.747013  475.152492  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(44)\n",
    "wine_dataset = pd.read_csv(\"wine_dataset.csv\")\n",
    "print(wine_dataset.info())\n",
    "wine_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 14)\n",
      "(5000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>Od_Hod_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.726791</td>\n",
       "      <td>0.085805</td>\n",
       "      <td>0.432125</td>\n",
       "      <td>0.200468</td>\n",
       "      <td>0.392663</td>\n",
       "      <td>0.452788</td>\n",
       "      <td>0.559874</td>\n",
       "      <td>0.477090</td>\n",
       "      <td>0.489749</td>\n",
       "      <td>0.163244</td>\n",
       "      <td>0.635628</td>\n",
       "      <td>0.584439</td>\n",
       "      <td>0.399009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.237919</td>\n",
       "      <td>0.142156</td>\n",
       "      <td>0.437079</td>\n",
       "      <td>0.357903</td>\n",
       "      <td>0.368467</td>\n",
       "      <td>0.599717</td>\n",
       "      <td>0.382811</td>\n",
       "      <td>0.322602</td>\n",
       "      <td>0.258369</td>\n",
       "      <td>0.665030</td>\n",
       "      <td>0.790293</td>\n",
       "      <td>0.571170</td>\n",
       "      <td>0.065151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.437744</td>\n",
       "      <td>0.220358</td>\n",
       "      <td>0.576004</td>\n",
       "      <td>0.564587</td>\n",
       "      <td>0.200303</td>\n",
       "      <td>0.326101</td>\n",
       "      <td>0.097921</td>\n",
       "      <td>0.662590</td>\n",
       "      <td>0.341220</td>\n",
       "      <td>0.640008</td>\n",
       "      <td>0.192992</td>\n",
       "      <td>0.156748</td>\n",
       "      <td>0.258989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.541419</td>\n",
       "      <td>0.232330</td>\n",
       "      <td>0.259309</td>\n",
       "      <td>0.252821</td>\n",
       "      <td>0.414189</td>\n",
       "      <td>0.581132</td>\n",
       "      <td>0.615985</td>\n",
       "      <td>0.261494</td>\n",
       "      <td>0.381721</td>\n",
       "      <td>0.438447</td>\n",
       "      <td>0.341653</td>\n",
       "      <td>0.884296</td>\n",
       "      <td>0.417983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.204211</td>\n",
       "      <td>0.440507</td>\n",
       "      <td>0.910246</td>\n",
       "      <td>0.337946</td>\n",
       "      <td>0.184095</td>\n",
       "      <td>0.430953</td>\n",
       "      <td>0.137943</td>\n",
       "      <td>0.273130</td>\n",
       "      <td>0.428986</td>\n",
       "      <td>0.771760</td>\n",
       "      <td>0.269215</td>\n",
       "      <td>0.559762</td>\n",
       "      <td>0.156864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   Alcohol  Malic_acid       Ash  Alcalinity_of_ash  Magnesium  \\\n",
       "0      1  0.726791    0.085805  0.432125           0.200468   0.392663   \n",
       "1      2  0.237919    0.142156  0.437079           0.357903   0.368467   \n",
       "2      3  0.437744    0.220358  0.576004           0.564587   0.200303   \n",
       "3      1  0.541419    0.232330  0.259309           0.252821   0.414189   \n",
       "4      3  0.204211    0.440507  0.910246           0.337946   0.184095   \n",
       "\n",
       "   Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  \\\n",
       "0       0.452788    0.559874              0.477090         0.489749   \n",
       "1       0.599717    0.382811              0.322602         0.258369   \n",
       "2       0.326101    0.097921              0.662590         0.341220   \n",
       "3       0.581132    0.615985              0.261494         0.381721   \n",
       "4       0.430953    0.137943              0.273130         0.428986   \n",
       "\n",
       "   Color_intensity       Hue  Od_Hod_of_diluted_wines   Proline  \n",
       "0         0.163244  0.635628                 0.584439  0.399009  \n",
       "1         0.665030  0.790293                 0.571170  0.065151  \n",
       "2         0.640008  0.192992                 0.156748  0.258989  \n",
       "3         0.438447  0.341653                 0.884296  0.417983  \n",
       "4         0.771760  0.269215                 0.559762  0.156864  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize features for better performance \n",
    "from sklearn import preprocessing\n",
    "target = wine_dataset[\"class\"]\n",
    "x = wine_dataset.values # convert to numpy array\n",
    "print(x.shape)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "print(x_scaled.shape)\n",
    "wine_dataset = pd.DataFrame(x_scaled, columns=wine_dataset.columns)\n",
    "wine_dataset[\"class\"] = target\n",
    "wine_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified sampling\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1 , test_size=0.2, random_state=30)\n",
    "for train_ind, test_ind in split.split(wine_dataset, wine_dataset[\"class\"]):\n",
    "    strat_train_set = wine_dataset.loc[train_ind]\n",
    "    strat_test_set = wine_dataset.loc[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4000 entries, 1725 to 3709\n",
      "Data columns (total 14 columns):\n",
      "class                      4000 non-null int64\n",
      "Alcohol                    4000 non-null float64\n",
      "Malic_acid                 4000 non-null float64\n",
      "Ash                        4000 non-null float64\n",
      "Alcalinity_of_ash          4000 non-null float64\n",
      "Magnesium                  4000 non-null float64\n",
      "Total_phenols              4000 non-null float64\n",
      "Flavanoids                 4000 non-null float64\n",
      "Nonflavanoid_phenols       4000 non-null float64\n",
      "Proanthocyanins            4000 non-null float64\n",
      "Color_intensity            4000 non-null float64\n",
      "Hue                        4000 non-null float64\n",
      "Od_Hod_of_diluted_wines    4000 non-null float64\n",
      "Proline                    4000 non-null float64\n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 468.8 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 387 to 4415\n",
      "Data columns (total 14 columns):\n",
      "class                      1000 non-null int64\n",
      "Alcohol                    1000 non-null float64\n",
      "Malic_acid                 1000 non-null float64\n",
      "Ash                        1000 non-null float64\n",
      "Alcalinity_of_ash          1000 non-null float64\n",
      "Magnesium                  1000 non-null float64\n",
      "Total_phenols              1000 non-null float64\n",
      "Flavanoids                 1000 non-null float64\n",
      "Nonflavanoid_phenols       1000 non-null float64\n",
      "Proanthocyanins            1000 non-null float64\n",
      "Color_intensity            1000 non-null float64\n",
      "Hue                        1000 non-null float64\n",
      "Od_Hod_of_diluted_wines    1000 non-null float64\n",
      "Proline                    1000 non-null float64\n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 117.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = strat_train_set\n",
    "test_set = strat_test_set\n",
    "# stratified sampling is not needed\n",
    "train_y = train_set[[\"class\"]]\n",
    "train_X = train_set.drop(\"class\", axis=1)\n",
    "test_y = test_set[[\"class\"]]\n",
    "test_X = test_set.drop(\"class\", axis=1)\n",
    "train_set.info(), test_set.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running nngs_sa\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed: 67.1min\n",
      "[Parallel(n_jobs=-2)]: Done 150 out of 150 | elapsed: 182.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************\n",
      "*** Run START ***\n",
      "*****************\n",
      "max_iters:[10000], schedule:[1], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ... -0.15103284  0.16559681\n",
      "  0.72446653]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
      "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.03], fitness:[4.0498]\n",
      "\t[ 0.54264129 -0.9584961   0.26729647 ... -0.15103284  0.16559681//  0.72446653]...\n",
      "\n",
      "max_iters:[10000], schedule:[1], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ... -0.15103284  0.16559681\n",
      "  0.72446653]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
      "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[10000], done:[True], time:[552.33], fitness:[0.2841]\n",
      "\t[ 0.54264129 -0.9584961   0.26729647 ... -0.35103284 -0.03440319//  0.72446653]...\n",
      "\n",
      "***************\n",
      "*** Run END ***\n",
      "***************\n",
      "Run time: 11504.123902384003\n",
      "Saving: [./sa/nn_test/nngs_sa__nn_test__run_stats_df__60C1A02C289073F79C23D3F5FDDDA347.csv]\n",
      "Saving: [./sa/nn_test/nngs_sa__nn_test__curves_df__60C1A02C289073F79C23D3F5FDDDA347.csv]\n",
      "Saving: [./sa/nn_test/nngs_sa__nn_test__cv_results_df__60C1A02C289073F79C23D3F5FDDDA347.csv]\n",
      "Saving: [./sa/nn_test/nngs_sa__nn_test__grid_search_results__60C1A02C289073F79C23D3F5FDDDA347.p]\n"
     ]
    }
   ],
   "source": [
    "from mlrose_hiive import ExpDecay\n",
    "f1_labs = partial(f1_score, average=\"weighted\")\n",
    "grid_search_parameters = ({\n",
    "  'schedule': [ExpDecay(1),ExpDecay(10),ExpDecay(25),ExpDecay(50), ExpDecay(100),ExpDecay(10000)],\n",
    "  'learning_rate': [0.0001, 0.001, 0.0025, 0.005, 0.01],  \n",
    "  'activation': [mlrose_hiive.neural.activation.relu],\n",
    "  'max_iters': [10000]\n",
    "})\n",
    "nnr = mlrose_hiive.NNGSRunner(x_train=train_X,\n",
    "                     y_train=pd.get_dummies(train_y.values.ravel()).values,\n",
    "                     x_test=test_X,\n",
    "                     y_test=pd.get_dummies(test_y.values.ravel()).values,\n",
    "                     experiment_name='nn_test',\n",
    "                     seed=10,\n",
    "                     output_directory=\"./sa\",\n",
    "                     hidden_layer_sizes=[[60,60]],                             \n",
    "                     algorithm=mlrose_hiive.algorithms.sa.simulated_annealing,\n",
    "                     grid_search_parameters=grid_search_parameters,\n",
    "                     grid_search_scorer_method=f1_labs,\n",
    "                     iteration_list=[10000],\n",
    "                     n_jobs=-2)\n",
    "results = nnr.run()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_iters</th>\n",
       "      <th>param_schedule</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>455.661446</td>\n",
       "      <td>11.332451</td>\n",
       "      <td>0.009031</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.908575</td>\n",
       "      <td>0.919977</td>\n",
       "      <td>0.892492</td>\n",
       "      <td>0.887450</td>\n",
       "      <td>0.889824</td>\n",
       "      <td>0.899664</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902499</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.903729</td>\n",
       "      <td>0.913430</td>\n",
       "      <td>0.905631</td>\n",
       "      <td>0.903744</td>\n",
       "      <td>0.006408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>494.492773</td>\n",
       "      <td>33.445781</td>\n",
       "      <td>0.016687</td>\n",
       "      <td>0.008782</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.902429</td>\n",
       "      <td>0.918676</td>\n",
       "      <td>0.892630</td>\n",
       "      <td>0.881229</td>\n",
       "      <td>0.892446</td>\n",
       "      <td>0.897482</td>\n",
       "      <td>0.012544</td>\n",
       "      <td>6</td>\n",
       "      <td>0.901580</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.903446</td>\n",
       "      <td>0.908440</td>\n",
       "      <td>0.906868</td>\n",
       "      <td>0.903067</td>\n",
       "      <td>0.004706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589.624544</td>\n",
       "      <td>95.495722</td>\n",
       "      <td>0.025037</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000</td>\n",
       "      <td>25</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.914953</td>\n",
       "      <td>0.892529</td>\n",
       "      <td>0.887269</td>\n",
       "      <td>0.891107</td>\n",
       "      <td>0.896675</td>\n",
       "      <td>0.009710</td>\n",
       "      <td>16</td>\n",
       "      <td>0.901867</td>\n",
       "      <td>0.894353</td>\n",
       "      <td>0.902188</td>\n",
       "      <td>0.905008</td>\n",
       "      <td>0.904706</td>\n",
       "      <td>0.901624</td>\n",
       "      <td>0.003852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>797.588046</td>\n",
       "      <td>3.060053</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000</td>\n",
       "      <td>50</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.893727</td>\n",
       "      <td>0.919934</td>\n",
       "      <td>0.887486</td>\n",
       "      <td>0.879887</td>\n",
       "      <td>0.878680</td>\n",
       "      <td>0.891943</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>26</td>\n",
       "      <td>0.899381</td>\n",
       "      <td>0.890343</td>\n",
       "      <td>0.903738</td>\n",
       "      <td>0.904643</td>\n",
       "      <td>0.901862</td>\n",
       "      <td>0.899993</td>\n",
       "      <td>0.005151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>792.857036</td>\n",
       "      <td>5.973250</td>\n",
       "      <td>0.017849</td>\n",
       "      <td>0.010339</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.901194</td>\n",
       "      <td>0.918716</td>\n",
       "      <td>0.888864</td>\n",
       "      <td>0.884868</td>\n",
       "      <td>0.893596</td>\n",
       "      <td>0.897447</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>11</td>\n",
       "      <td>0.906249</td>\n",
       "      <td>0.897191</td>\n",
       "      <td>0.900610</td>\n",
       "      <td>0.909358</td>\n",
       "      <td>0.904064</td>\n",
       "      <td>0.903495</td>\n",
       "      <td>0.004251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>808.152015</td>\n",
       "      <td>3.754371</td>\n",
       "      <td>0.017916</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.902394</td>\n",
       "      <td>0.913805</td>\n",
       "      <td>0.883768</td>\n",
       "      <td>0.874848</td>\n",
       "      <td>0.897389</td>\n",
       "      <td>0.894441</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>21</td>\n",
       "      <td>0.902487</td>\n",
       "      <td>0.892831</td>\n",
       "      <td>0.899988</td>\n",
       "      <td>0.906862</td>\n",
       "      <td>0.906259</td>\n",
       "      <td>0.901686</td>\n",
       "      <td>0.005092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>815.847775</td>\n",
       "      <td>8.894109</td>\n",
       "      <td>0.021136</td>\n",
       "      <td>0.011278</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.908575</td>\n",
       "      <td>0.919977</td>\n",
       "      <td>0.892492</td>\n",
       "      <td>0.887450</td>\n",
       "      <td>0.889824</td>\n",
       "      <td>0.899664</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902499</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.903729</td>\n",
       "      <td>0.913430</td>\n",
       "      <td>0.905631</td>\n",
       "      <td>0.903744</td>\n",
       "      <td>0.006408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>682.288693</td>\n",
       "      <td>6.230099</td>\n",
       "      <td>0.020857</td>\n",
       "      <td>0.009826</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.902429</td>\n",
       "      <td>0.918676</td>\n",
       "      <td>0.892630</td>\n",
       "      <td>0.881229</td>\n",
       "      <td>0.892446</td>\n",
       "      <td>0.897482</td>\n",
       "      <td>0.012544</td>\n",
       "      <td>6</td>\n",
       "      <td>0.901580</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.903446</td>\n",
       "      <td>0.908440</td>\n",
       "      <td>0.906868</td>\n",
       "      <td>0.903067</td>\n",
       "      <td>0.004706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>612.437017</td>\n",
       "      <td>56.664757</td>\n",
       "      <td>0.023591</td>\n",
       "      <td>0.009562</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10000</td>\n",
       "      <td>25</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.914953</td>\n",
       "      <td>0.892529</td>\n",
       "      <td>0.887269</td>\n",
       "      <td>0.891107</td>\n",
       "      <td>0.896675</td>\n",
       "      <td>0.009710</td>\n",
       "      <td>16</td>\n",
       "      <td>0.901867</td>\n",
       "      <td>0.894353</td>\n",
       "      <td>0.902188</td>\n",
       "      <td>0.905008</td>\n",
       "      <td>0.904706</td>\n",
       "      <td>0.901624</td>\n",
       "      <td>0.003852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>545.339897</td>\n",
       "      <td>28.705836</td>\n",
       "      <td>0.012122</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10000</td>\n",
       "      <td>50</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.893727</td>\n",
       "      <td>0.919934</td>\n",
       "      <td>0.887486</td>\n",
       "      <td>0.879887</td>\n",
       "      <td>0.878680</td>\n",
       "      <td>0.891943</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>26</td>\n",
       "      <td>0.899381</td>\n",
       "      <td>0.890343</td>\n",
       "      <td>0.903738</td>\n",
       "      <td>0.904643</td>\n",
       "      <td>0.901862</td>\n",
       "      <td>0.899993</td>\n",
       "      <td>0.005151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>481.272924</td>\n",
       "      <td>6.481241</td>\n",
       "      <td>0.010805</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.901194</td>\n",
       "      <td>0.918716</td>\n",
       "      <td>0.888864</td>\n",
       "      <td>0.884868</td>\n",
       "      <td>0.893596</td>\n",
       "      <td>0.897447</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>11</td>\n",
       "      <td>0.906249</td>\n",
       "      <td>0.897191</td>\n",
       "      <td>0.900610</td>\n",
       "      <td>0.909358</td>\n",
       "      <td>0.904064</td>\n",
       "      <td>0.903495</td>\n",
       "      <td>0.004251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>435.950005</td>\n",
       "      <td>21.450989</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.902394</td>\n",
       "      <td>0.913805</td>\n",
       "      <td>0.883768</td>\n",
       "      <td>0.874848</td>\n",
       "      <td>0.897389</td>\n",
       "      <td>0.894441</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>21</td>\n",
       "      <td>0.902487</td>\n",
       "      <td>0.892831</td>\n",
       "      <td>0.899988</td>\n",
       "      <td>0.906862</td>\n",
       "      <td>0.906259</td>\n",
       "      <td>0.901686</td>\n",
       "      <td>0.005092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>423.601397</td>\n",
       "      <td>3.009464</td>\n",
       "      <td>0.010676</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.908575</td>\n",
       "      <td>0.919977</td>\n",
       "      <td>0.892492</td>\n",
       "      <td>0.887450</td>\n",
       "      <td>0.889824</td>\n",
       "      <td>0.899664</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902499</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.903729</td>\n",
       "      <td>0.913430</td>\n",
       "      <td>0.905631</td>\n",
       "      <td>0.903744</td>\n",
       "      <td>0.006408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>424.574330</td>\n",
       "      <td>3.600481</td>\n",
       "      <td>0.015401</td>\n",
       "      <td>0.010777</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.902429</td>\n",
       "      <td>0.918676</td>\n",
       "      <td>0.892630</td>\n",
       "      <td>0.881229</td>\n",
       "      <td>0.892446</td>\n",
       "      <td>0.897482</td>\n",
       "      <td>0.012544</td>\n",
       "      <td>6</td>\n",
       "      <td>0.901580</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.903446</td>\n",
       "      <td>0.908440</td>\n",
       "      <td>0.906868</td>\n",
       "      <td>0.903067</td>\n",
       "      <td>0.004706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>425.737764</td>\n",
       "      <td>3.153168</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>10000</td>\n",
       "      <td>25</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.914953</td>\n",
       "      <td>0.892529</td>\n",
       "      <td>0.887269</td>\n",
       "      <td>0.891107</td>\n",
       "      <td>0.896675</td>\n",
       "      <td>0.009710</td>\n",
       "      <td>16</td>\n",
       "      <td>0.901867</td>\n",
       "      <td>0.894353</td>\n",
       "      <td>0.902188</td>\n",
       "      <td>0.905008</td>\n",
       "      <td>0.904706</td>\n",
       "      <td>0.901624</td>\n",
       "      <td>0.003852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>426.585878</td>\n",
       "      <td>7.880040</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>10000</td>\n",
       "      <td>50</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.893727</td>\n",
       "      <td>0.919934</td>\n",
       "      <td>0.887486</td>\n",
       "      <td>0.879887</td>\n",
       "      <td>0.878680</td>\n",
       "      <td>0.891943</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>26</td>\n",
       "      <td>0.899381</td>\n",
       "      <td>0.890343</td>\n",
       "      <td>0.903738</td>\n",
       "      <td>0.904643</td>\n",
       "      <td>0.901862</td>\n",
       "      <td>0.899993</td>\n",
       "      <td>0.005151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>426.275565</td>\n",
       "      <td>4.584343</td>\n",
       "      <td>0.010069</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.901194</td>\n",
       "      <td>0.918716</td>\n",
       "      <td>0.888864</td>\n",
       "      <td>0.884868</td>\n",
       "      <td>0.893596</td>\n",
       "      <td>0.897447</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>11</td>\n",
       "      <td>0.906249</td>\n",
       "      <td>0.897191</td>\n",
       "      <td>0.900610</td>\n",
       "      <td>0.909358</td>\n",
       "      <td>0.904064</td>\n",
       "      <td>0.903495</td>\n",
       "      <td>0.004251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>428.043324</td>\n",
       "      <td>2.838137</td>\n",
       "      <td>0.013832</td>\n",
       "      <td>0.006004</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.902394</td>\n",
       "      <td>0.913805</td>\n",
       "      <td>0.883768</td>\n",
       "      <td>0.874848</td>\n",
       "      <td>0.897389</td>\n",
       "      <td>0.894441</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>21</td>\n",
       "      <td>0.902487</td>\n",
       "      <td>0.892831</td>\n",
       "      <td>0.899988</td>\n",
       "      <td>0.906862</td>\n",
       "      <td>0.906259</td>\n",
       "      <td>0.901686</td>\n",
       "      <td>0.005092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>424.419546</td>\n",
       "      <td>4.929777</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.908575</td>\n",
       "      <td>0.919977</td>\n",
       "      <td>0.892492</td>\n",
       "      <td>0.887450</td>\n",
       "      <td>0.889824</td>\n",
       "      <td>0.899664</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902499</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.903729</td>\n",
       "      <td>0.913430</td>\n",
       "      <td>0.905631</td>\n",
       "      <td>0.903744</td>\n",
       "      <td>0.006408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>427.785286</td>\n",
       "      <td>1.735166</td>\n",
       "      <td>0.009826</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.902429</td>\n",
       "      <td>0.918676</td>\n",
       "      <td>0.892630</td>\n",
       "      <td>0.881229</td>\n",
       "      <td>0.892446</td>\n",
       "      <td>0.897482</td>\n",
       "      <td>0.012544</td>\n",
       "      <td>6</td>\n",
       "      <td>0.901580</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.903446</td>\n",
       "      <td>0.908440</td>\n",
       "      <td>0.906868</td>\n",
       "      <td>0.903067</td>\n",
       "      <td>0.004706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>429.899123</td>\n",
       "      <td>3.597371</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>10000</td>\n",
       "      <td>25</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.914953</td>\n",
       "      <td>0.892529</td>\n",
       "      <td>0.887269</td>\n",
       "      <td>0.891107</td>\n",
       "      <td>0.896675</td>\n",
       "      <td>0.009710</td>\n",
       "      <td>16</td>\n",
       "      <td>0.901867</td>\n",
       "      <td>0.894353</td>\n",
       "      <td>0.902188</td>\n",
       "      <td>0.905008</td>\n",
       "      <td>0.904706</td>\n",
       "      <td>0.901624</td>\n",
       "      <td>0.003852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>430.873634</td>\n",
       "      <td>2.126578</td>\n",
       "      <td>0.009562</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>10000</td>\n",
       "      <td>50</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.893727</td>\n",
       "      <td>0.919934</td>\n",
       "      <td>0.887486</td>\n",
       "      <td>0.879887</td>\n",
       "      <td>0.878680</td>\n",
       "      <td>0.891943</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>26</td>\n",
       "      <td>0.899381</td>\n",
       "      <td>0.890343</td>\n",
       "      <td>0.903738</td>\n",
       "      <td>0.904643</td>\n",
       "      <td>0.901862</td>\n",
       "      <td>0.899993</td>\n",
       "      <td>0.005151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>429.559877</td>\n",
       "      <td>3.363521</td>\n",
       "      <td>0.010559</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.901194</td>\n",
       "      <td>0.918716</td>\n",
       "      <td>0.888864</td>\n",
       "      <td>0.884868</td>\n",
       "      <td>0.893596</td>\n",
       "      <td>0.897447</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>11</td>\n",
       "      <td>0.906249</td>\n",
       "      <td>0.897191</td>\n",
       "      <td>0.900610</td>\n",
       "      <td>0.909358</td>\n",
       "      <td>0.904064</td>\n",
       "      <td>0.903495</td>\n",
       "      <td>0.004251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>433.602247</td>\n",
       "      <td>4.938469</td>\n",
       "      <td>0.009523</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.902394</td>\n",
       "      <td>0.913805</td>\n",
       "      <td>0.883768</td>\n",
       "      <td>0.874848</td>\n",
       "      <td>0.897389</td>\n",
       "      <td>0.894441</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>21</td>\n",
       "      <td>0.902487</td>\n",
       "      <td>0.892831</td>\n",
       "      <td>0.899988</td>\n",
       "      <td>0.906862</td>\n",
       "      <td>0.906259</td>\n",
       "      <td>0.901686</td>\n",
       "      <td>0.005092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>429.639917</td>\n",
       "      <td>2.333711</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.908575</td>\n",
       "      <td>0.919977</td>\n",
       "      <td>0.892492</td>\n",
       "      <td>0.887450</td>\n",
       "      <td>0.889824</td>\n",
       "      <td>0.899664</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902499</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.903729</td>\n",
       "      <td>0.913430</td>\n",
       "      <td>0.905631</td>\n",
       "      <td>0.903744</td>\n",
       "      <td>0.006408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>426.289885</td>\n",
       "      <td>6.434674</td>\n",
       "      <td>0.013602</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.902429</td>\n",
       "      <td>0.918676</td>\n",
       "      <td>0.892630</td>\n",
       "      <td>0.881229</td>\n",
       "      <td>0.892446</td>\n",
       "      <td>0.897482</td>\n",
       "      <td>0.012544</td>\n",
       "      <td>6</td>\n",
       "      <td>0.901580</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.903446</td>\n",
       "      <td>0.908440</td>\n",
       "      <td>0.906868</td>\n",
       "      <td>0.903067</td>\n",
       "      <td>0.004706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>428.307986</td>\n",
       "      <td>9.252872</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.009255</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10000</td>\n",
       "      <td>25</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.914953</td>\n",
       "      <td>0.892529</td>\n",
       "      <td>0.887269</td>\n",
       "      <td>0.891107</td>\n",
       "      <td>0.896675</td>\n",
       "      <td>0.009710</td>\n",
       "      <td>16</td>\n",
       "      <td>0.901867</td>\n",
       "      <td>0.894353</td>\n",
       "      <td>0.902188</td>\n",
       "      <td>0.905008</td>\n",
       "      <td>0.904706</td>\n",
       "      <td>0.901624</td>\n",
       "      <td>0.003852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>435.881998</td>\n",
       "      <td>4.446335</td>\n",
       "      <td>0.014201</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10000</td>\n",
       "      <td>50</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.893727</td>\n",
       "      <td>0.919934</td>\n",
       "      <td>0.887486</td>\n",
       "      <td>0.879887</td>\n",
       "      <td>0.878680</td>\n",
       "      <td>0.891943</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>26</td>\n",
       "      <td>0.899381</td>\n",
       "      <td>0.890343</td>\n",
       "      <td>0.903738</td>\n",
       "      <td>0.904643</td>\n",
       "      <td>0.901862</td>\n",
       "      <td>0.899993</td>\n",
       "      <td>0.005151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>426.991286</td>\n",
       "      <td>5.408516</td>\n",
       "      <td>0.014294</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.901194</td>\n",
       "      <td>0.918716</td>\n",
       "      <td>0.888864</td>\n",
       "      <td>0.884868</td>\n",
       "      <td>0.893596</td>\n",
       "      <td>0.897447</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>11</td>\n",
       "      <td>0.906249</td>\n",
       "      <td>0.897191</td>\n",
       "      <td>0.900610</td>\n",
       "      <td>0.909358</td>\n",
       "      <td>0.904064</td>\n",
       "      <td>0.903495</td>\n",
       "      <td>0.004251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>333.415195</td>\n",
       "      <td>81.832864</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.902394</td>\n",
       "      <td>0.913805</td>\n",
       "      <td>0.883768</td>\n",
       "      <td>0.874848</td>\n",
       "      <td>0.897389</td>\n",
       "      <td>0.894441</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>21</td>\n",
       "      <td>0.902487</td>\n",
       "      <td>0.892831</td>\n",
       "      <td>0.899988</td>\n",
       "      <td>0.906862</td>\n",
       "      <td>0.906259</td>\n",
       "      <td>0.901686</td>\n",
       "      <td>0.005092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      455.661446     11.332451         0.009031        0.000442   \n",
       "1      494.492773     33.445781         0.016687        0.008782   \n",
       "2      589.624544     95.495722         0.025037        0.005916   \n",
       "3      797.588046      3.060053         0.020240        0.010920   \n",
       "4      792.857036      5.973250         0.017849        0.010339   \n",
       "5      808.152015      3.754371         0.017916        0.007552   \n",
       "6      815.847775      8.894109         0.021136        0.011278   \n",
       "7      682.288693      6.230099         0.020857        0.009826   \n",
       "8      612.437017     56.664757         0.023591        0.009562   \n",
       "9      545.339897     28.705836         0.012122        0.002824   \n",
       "10     481.272924      6.481241         0.010805        0.002908   \n",
       "11     435.950005     21.450989         0.009923        0.002657   \n",
       "12     423.601397      3.009464         0.010676        0.003188   \n",
       "13     424.574330      3.600481         0.015401        0.010777   \n",
       "14     425.737764      3.153168         0.009304        0.001574   \n",
       "15     426.585878      7.880040         0.008830        0.001315   \n",
       "16     426.275565      4.584343         0.010069        0.001290   \n",
       "17     428.043324      2.838137         0.013832        0.006004   \n",
       "18     424.419546      4.929777         0.015066        0.009027   \n",
       "19     427.785286      1.735166         0.009826        0.000786   \n",
       "20     429.899123      3.597371         0.009024        0.001537   \n",
       "21     430.873634      2.126578         0.009562        0.000614   \n",
       "22     429.559877      3.363521         0.010559        0.000899   \n",
       "23     433.602247      4.938469         0.009523        0.001220   \n",
       "24     429.639917      2.333711         0.008593        0.001767   \n",
       "25     426.289885      6.434674         0.013602        0.005475   \n",
       "26     428.307986      9.252872         0.019358        0.009255   \n",
       "27     435.881998      4.446335         0.014201        0.005831   \n",
       "28     426.991286      5.408516         0.014294        0.014282   \n",
       "29     333.415195     81.832864         0.006277        0.001925   \n",
       "\n",
       "   param_activation param_hidden_layer_sizes  param_learning_rate  \\\n",
       "0              relu                 [60, 60]               0.0001   \n",
       "1              relu                 [60, 60]               0.0001   \n",
       "2              relu                 [60, 60]               0.0001   \n",
       "3              relu                 [60, 60]               0.0001   \n",
       "4              relu                 [60, 60]               0.0001   \n",
       "5              relu                 [60, 60]               0.0001   \n",
       "6              relu                 [60, 60]               0.0010   \n",
       "7              relu                 [60, 60]               0.0010   \n",
       "8              relu                 [60, 60]               0.0010   \n",
       "9              relu                 [60, 60]               0.0010   \n",
       "10             relu                 [60, 60]               0.0010   \n",
       "11             relu                 [60, 60]               0.0010   \n",
       "12             relu                 [60, 60]               0.0025   \n",
       "13             relu                 [60, 60]               0.0025   \n",
       "14             relu                 [60, 60]               0.0025   \n",
       "15             relu                 [60, 60]               0.0025   \n",
       "16             relu                 [60, 60]               0.0025   \n",
       "17             relu                 [60, 60]               0.0025   \n",
       "18             relu                 [60, 60]               0.0050   \n",
       "19             relu                 [60, 60]               0.0050   \n",
       "20             relu                 [60, 60]               0.0050   \n",
       "21             relu                 [60, 60]               0.0050   \n",
       "22             relu                 [60, 60]               0.0050   \n",
       "23             relu                 [60, 60]               0.0050   \n",
       "24             relu                 [60, 60]               0.0100   \n",
       "25             relu                 [60, 60]               0.0100   \n",
       "26             relu                 [60, 60]               0.0100   \n",
       "27             relu                 [60, 60]               0.0100   \n",
       "28             relu                 [60, 60]               0.0100   \n",
       "29             relu                 [60, 60]               0.0100   \n",
       "\n",
       "    param_max_iters param_schedule  \\\n",
       "0             10000              1   \n",
       "1             10000             10   \n",
       "2             10000             25   \n",
       "3             10000             50   \n",
       "4             10000            100   \n",
       "5             10000          10000   \n",
       "6             10000              1   \n",
       "7             10000             10   \n",
       "8             10000             25   \n",
       "9             10000             50   \n",
       "10            10000            100   \n",
       "11            10000          10000   \n",
       "12            10000              1   \n",
       "13            10000             10   \n",
       "14            10000             25   \n",
       "15            10000             50   \n",
       "16            10000            100   \n",
       "17            10000          10000   \n",
       "18            10000              1   \n",
       "19            10000             10   \n",
       "20            10000             25   \n",
       "21            10000             50   \n",
       "22            10000            100   \n",
       "23            10000          10000   \n",
       "24            10000              1   \n",
       "25            10000             10   \n",
       "26            10000             25   \n",
       "27            10000             50   \n",
       "28            10000            100   \n",
       "29            10000          10000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'activation': <function relu at 0x7f546380f20...           0.908575   \n",
       "1   {'activation': <function relu at 0x7f546380f20...           0.902429   \n",
       "2   {'activation': <function relu at 0x7f546380f20...           0.897516   \n",
       "3   {'activation': <function relu at 0x7f546380f20...           0.893727   \n",
       "4   {'activation': <function relu at 0x7f546380f20...           0.901194   \n",
       "5   {'activation': <function relu at 0x7f546380f20...           0.902394   \n",
       "6   {'activation': <function relu at 0x7f546380f20...           0.908575   \n",
       "7   {'activation': <function relu at 0x7f546380f20...           0.902429   \n",
       "8   {'activation': <function relu at 0x7f546380f20...           0.897516   \n",
       "9   {'activation': <function relu at 0x7f546380f20...           0.893727   \n",
       "10  {'activation': <function relu at 0x7f546380f20...           0.901194   \n",
       "11  {'activation': <function relu at 0x7f546380f20...           0.902394   \n",
       "12  {'activation': <function relu at 0x7f546380f20...           0.908575   \n",
       "13  {'activation': <function relu at 0x7f546380f20...           0.902429   \n",
       "14  {'activation': <function relu at 0x7f546380f20...           0.897516   \n",
       "15  {'activation': <function relu at 0x7f546380f20...           0.893727   \n",
       "16  {'activation': <function relu at 0x7f546380f20...           0.901194   \n",
       "17  {'activation': <function relu at 0x7f546380f20...           0.902394   \n",
       "18  {'activation': <function relu at 0x7f546380f20...           0.908575   \n",
       "19  {'activation': <function relu at 0x7f546380f20...           0.902429   \n",
       "20  {'activation': <function relu at 0x7f546380f20...           0.897516   \n",
       "21  {'activation': <function relu at 0x7f546380f20...           0.893727   \n",
       "22  {'activation': <function relu at 0x7f546380f20...           0.901194   \n",
       "23  {'activation': <function relu at 0x7f546380f20...           0.902394   \n",
       "24  {'activation': <function relu at 0x7f546380f20...           0.908575   \n",
       "25  {'activation': <function relu at 0x7f546380f20...           0.902429   \n",
       "26  {'activation': <function relu at 0x7f546380f20...           0.897516   \n",
       "27  {'activation': <function relu at 0x7f546380f20...           0.893727   \n",
       "28  {'activation': <function relu at 0x7f546380f20...           0.901194   \n",
       "29  {'activation': <function relu at 0x7f546380f20...           0.902394   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.919977           0.892492           0.887450   \n",
       "1            0.918676           0.892630           0.881229   \n",
       "2            0.914953           0.892529           0.887269   \n",
       "3            0.919934           0.887486           0.879887   \n",
       "4            0.918716           0.888864           0.884868   \n",
       "5            0.913805           0.883768           0.874848   \n",
       "6            0.919977           0.892492           0.887450   \n",
       "7            0.918676           0.892630           0.881229   \n",
       "8            0.914953           0.892529           0.887269   \n",
       "9            0.919934           0.887486           0.879887   \n",
       "10           0.918716           0.888864           0.884868   \n",
       "11           0.913805           0.883768           0.874848   \n",
       "12           0.919977           0.892492           0.887450   \n",
       "13           0.918676           0.892630           0.881229   \n",
       "14           0.914953           0.892529           0.887269   \n",
       "15           0.919934           0.887486           0.879887   \n",
       "16           0.918716           0.888864           0.884868   \n",
       "17           0.913805           0.883768           0.874848   \n",
       "18           0.919977           0.892492           0.887450   \n",
       "19           0.918676           0.892630           0.881229   \n",
       "20           0.914953           0.892529           0.887269   \n",
       "21           0.919934           0.887486           0.879887   \n",
       "22           0.918716           0.888864           0.884868   \n",
       "23           0.913805           0.883768           0.874848   \n",
       "24           0.919977           0.892492           0.887450   \n",
       "25           0.918676           0.892630           0.881229   \n",
       "26           0.914953           0.892529           0.887269   \n",
       "27           0.919934           0.887486           0.879887   \n",
       "28           0.918716           0.888864           0.884868   \n",
       "29           0.913805           0.883768           0.874848   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0            0.889824         0.899664        0.012566                1   \n",
       "1            0.892446         0.897482        0.012544                6   \n",
       "2            0.891107         0.896675        0.009710               16   \n",
       "3            0.878680         0.891943        0.015019               26   \n",
       "4            0.893596         0.897447        0.011943               11   \n",
       "5            0.897389         0.894441        0.013746               21   \n",
       "6            0.889824         0.899664        0.012566                1   \n",
       "7            0.892446         0.897482        0.012544                6   \n",
       "8            0.891107         0.896675        0.009710               16   \n",
       "9            0.878680         0.891943        0.015019               26   \n",
       "10           0.893596         0.897447        0.011943               11   \n",
       "11           0.897389         0.894441        0.013746               21   \n",
       "12           0.889824         0.899664        0.012566                1   \n",
       "13           0.892446         0.897482        0.012544                6   \n",
       "14           0.891107         0.896675        0.009710               16   \n",
       "15           0.878680         0.891943        0.015019               26   \n",
       "16           0.893596         0.897447        0.011943               11   \n",
       "17           0.897389         0.894441        0.013746               21   \n",
       "18           0.889824         0.899664        0.012566                1   \n",
       "19           0.892446         0.897482        0.012544                6   \n",
       "20           0.891107         0.896675        0.009710               16   \n",
       "21           0.878680         0.891943        0.015019               26   \n",
       "22           0.893596         0.897447        0.011943               11   \n",
       "23           0.897389         0.894441        0.013746               21   \n",
       "24           0.889824         0.899664        0.012566                1   \n",
       "25           0.892446         0.897482        0.012544                6   \n",
       "26           0.891107         0.896675        0.009710               16   \n",
       "27           0.878680         0.891943        0.015019               26   \n",
       "28           0.893596         0.897447        0.011943               11   \n",
       "29           0.897389         0.894441        0.013746               21   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0             0.902499            0.893431            0.903729   \n",
       "1             0.901580            0.895000            0.903446   \n",
       "2             0.901867            0.894353            0.902188   \n",
       "3             0.899381            0.890343            0.903738   \n",
       "4             0.906249            0.897191            0.900610   \n",
       "5             0.902487            0.892831            0.899988   \n",
       "6             0.902499            0.893431            0.903729   \n",
       "7             0.901580            0.895000            0.903446   \n",
       "8             0.901867            0.894353            0.902188   \n",
       "9             0.899381            0.890343            0.903738   \n",
       "10            0.906249            0.897191            0.900610   \n",
       "11            0.902487            0.892831            0.899988   \n",
       "12            0.902499            0.893431            0.903729   \n",
       "13            0.901580            0.895000            0.903446   \n",
       "14            0.901867            0.894353            0.902188   \n",
       "15            0.899381            0.890343            0.903738   \n",
       "16            0.906249            0.897191            0.900610   \n",
       "17            0.902487            0.892831            0.899988   \n",
       "18            0.902499            0.893431            0.903729   \n",
       "19            0.901580            0.895000            0.903446   \n",
       "20            0.901867            0.894353            0.902188   \n",
       "21            0.899381            0.890343            0.903738   \n",
       "22            0.906249            0.897191            0.900610   \n",
       "23            0.902487            0.892831            0.899988   \n",
       "24            0.902499            0.893431            0.903729   \n",
       "25            0.901580            0.895000            0.903446   \n",
       "26            0.901867            0.894353            0.902188   \n",
       "27            0.899381            0.890343            0.903738   \n",
       "28            0.906249            0.897191            0.900610   \n",
       "29            0.902487            0.892831            0.899988   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0             0.913430            0.905631          0.903744         0.006408  \n",
       "1             0.908440            0.906868          0.903067         0.004706  \n",
       "2             0.905008            0.904706          0.901624         0.003852  \n",
       "3             0.904643            0.901862          0.899993         0.005151  \n",
       "4             0.909358            0.904064          0.903495         0.004251  \n",
       "5             0.906862            0.906259          0.901686         0.005092  \n",
       "6             0.913430            0.905631          0.903744         0.006408  \n",
       "7             0.908440            0.906868          0.903067         0.004706  \n",
       "8             0.905008            0.904706          0.901624         0.003852  \n",
       "9             0.904643            0.901862          0.899993         0.005151  \n",
       "10            0.909358            0.904064          0.903495         0.004251  \n",
       "11            0.906862            0.906259          0.901686         0.005092  \n",
       "12            0.913430            0.905631          0.903744         0.006408  \n",
       "13            0.908440            0.906868          0.903067         0.004706  \n",
       "14            0.905008            0.904706          0.901624         0.003852  \n",
       "15            0.904643            0.901862          0.899993         0.005151  \n",
       "16            0.909358            0.904064          0.903495         0.004251  \n",
       "17            0.906862            0.906259          0.901686         0.005092  \n",
       "18            0.913430            0.905631          0.903744         0.006408  \n",
       "19            0.908440            0.906868          0.903067         0.004706  \n",
       "20            0.905008            0.904706          0.901624         0.003852  \n",
       "21            0.904643            0.901862          0.899993         0.005151  \n",
       "22            0.909358            0.904064          0.903495         0.004251  \n",
       "23            0.906862            0.906259          0.901686         0.005092  \n",
       "24            0.913430            0.905631          0.903744         0.006408  \n",
       "25            0.908440            0.906868          0.903067         0.004706  \n",
       "26            0.905008            0.904706          0.901624         0.003852  \n",
       "27            0.904643            0.901862          0.899993         0.005151  \n",
       "28            0.909358            0.904064          0.903495         0.004251  \n",
       "29            0.906862            0.906259          0.901686         0.005092  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_iters</th>\n",
       "      <th>param_schedule</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>455.661446</td>\n",
       "      <td>11.332451</td>\n",
       "      <td>0.009031</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.908575</td>\n",
       "      <td>0.919977</td>\n",
       "      <td>0.892492</td>\n",
       "      <td>0.887450</td>\n",
       "      <td>0.889824</td>\n",
       "      <td>0.899664</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902499</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.903729</td>\n",
       "      <td>0.913430</td>\n",
       "      <td>0.905631</td>\n",
       "      <td>0.903744</td>\n",
       "      <td>0.006408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>494.492773</td>\n",
       "      <td>33.445781</td>\n",
       "      <td>0.016687</td>\n",
       "      <td>0.008782</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.902429</td>\n",
       "      <td>0.918676</td>\n",
       "      <td>0.892630</td>\n",
       "      <td>0.881229</td>\n",
       "      <td>0.892446</td>\n",
       "      <td>0.897482</td>\n",
       "      <td>0.012544</td>\n",
       "      <td>6</td>\n",
       "      <td>0.901580</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.903446</td>\n",
       "      <td>0.908440</td>\n",
       "      <td>0.906868</td>\n",
       "      <td>0.903067</td>\n",
       "      <td>0.004706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589.624544</td>\n",
       "      <td>95.495722</td>\n",
       "      <td>0.025037</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000</td>\n",
       "      <td>25</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.914953</td>\n",
       "      <td>0.892529</td>\n",
       "      <td>0.887269</td>\n",
       "      <td>0.891107</td>\n",
       "      <td>0.896675</td>\n",
       "      <td>0.009710</td>\n",
       "      <td>16</td>\n",
       "      <td>0.901867</td>\n",
       "      <td>0.894353</td>\n",
       "      <td>0.902188</td>\n",
       "      <td>0.905008</td>\n",
       "      <td>0.904706</td>\n",
       "      <td>0.901624</td>\n",
       "      <td>0.003852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>797.588046</td>\n",
       "      <td>3.060053</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000</td>\n",
       "      <td>50</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.893727</td>\n",
       "      <td>0.919934</td>\n",
       "      <td>0.887486</td>\n",
       "      <td>0.879887</td>\n",
       "      <td>0.878680</td>\n",
       "      <td>0.891943</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>26</td>\n",
       "      <td>0.899381</td>\n",
       "      <td>0.890343</td>\n",
       "      <td>0.903738</td>\n",
       "      <td>0.904643</td>\n",
       "      <td>0.901862</td>\n",
       "      <td>0.899993</td>\n",
       "      <td>0.005151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>792.857036</td>\n",
       "      <td>5.973250</td>\n",
       "      <td>0.017849</td>\n",
       "      <td>0.010339</td>\n",
       "      <td>relu</td>\n",
       "      <td>[60, 60]</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': &lt;function relu at 0x7f546380f20...</td>\n",
       "      <td>0.901194</td>\n",
       "      <td>0.918716</td>\n",
       "      <td>0.888864</td>\n",
       "      <td>0.884868</td>\n",
       "      <td>0.893596</td>\n",
       "      <td>0.897447</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>11</td>\n",
       "      <td>0.906249</td>\n",
       "      <td>0.897191</td>\n",
       "      <td>0.900610</td>\n",
       "      <td>0.909358</td>\n",
       "      <td>0.904064</td>\n",
       "      <td>0.903495</td>\n",
       "      <td>0.004251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     455.661446     11.332451         0.009031        0.000442   \n",
       "1     494.492773     33.445781         0.016687        0.008782   \n",
       "2     589.624544     95.495722         0.025037        0.005916   \n",
       "3     797.588046      3.060053         0.020240        0.010920   \n",
       "4     792.857036      5.973250         0.017849        0.010339   \n",
       "\n",
       "  param_activation param_hidden_layer_sizes  param_learning_rate  \\\n",
       "0             relu                 [60, 60]               0.0001   \n",
       "1             relu                 [60, 60]               0.0001   \n",
       "2             relu                 [60, 60]               0.0001   \n",
       "3             relu                 [60, 60]               0.0001   \n",
       "4             relu                 [60, 60]               0.0001   \n",
       "\n",
       "   param_max_iters param_schedule  \\\n",
       "0            10000              1   \n",
       "1            10000             10   \n",
       "2            10000             25   \n",
       "3            10000             50   \n",
       "4            10000            100   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'activation': <function relu at 0x7f546380f20...           0.908575   \n",
       "1  {'activation': <function relu at 0x7f546380f20...           0.902429   \n",
       "2  {'activation': <function relu at 0x7f546380f20...           0.897516   \n",
       "3  {'activation': <function relu at 0x7f546380f20...           0.893727   \n",
       "4  {'activation': <function relu at 0x7f546380f20...           0.901194   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.919977           0.892492           0.887450           0.889824   \n",
       "1           0.918676           0.892630           0.881229           0.892446   \n",
       "2           0.914953           0.892529           0.887269           0.891107   \n",
       "3           0.919934           0.887486           0.879887           0.878680   \n",
       "4           0.918716           0.888864           0.884868           0.893596   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.899664        0.012566                1            0.902499   \n",
       "1         0.897482        0.012544                6            0.901580   \n",
       "2         0.896675        0.009710               16            0.901867   \n",
       "3         0.891943        0.015019               26            0.899381   \n",
       "4         0.897447        0.011943               11            0.906249   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.893431            0.903729            0.913430   \n",
       "1            0.895000            0.903446            0.908440   \n",
       "2            0.894353            0.902188            0.905008   \n",
       "3            0.890343            0.903738            0.904643   \n",
       "4            0.897191            0.900610            0.909358   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.905631          0.903744         0.006408  \n",
       "1            0.906868          0.903067         0.004706  \n",
       "2            0.904706          0.901624         0.003852  \n",
       "3            0.901862          0.899993         0.005151  \n",
       "4            0.904064          0.903495         0.004251  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       315\n",
      "           1       0.91      0.92      0.91       403\n",
      "           2       0.92      0.88      0.90       282\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      " samples avg       0.91      0.91      0.91      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "y_pred = results[3].predict(test_X)\n",
    "print(classification_report(pd.get_dummies(test_y.values.ravel()).values, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      1262\n",
      "           1       0.89      0.91      0.90      1610\n",
      "           2       0.89      0.89      0.89      1128\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      4000\n",
      "   macro avg       0.90      0.90      0.90      4000\n",
      "weighted avg       0.90      0.90      0.90      4000\n",
      " samples avg       0.90      0.90      0.90      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = results[3].predict(train_X)\n",
    "print(classification_report(pd.get_dummies(train_y.values.ravel()).values, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
